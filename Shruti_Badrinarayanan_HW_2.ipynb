{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment 2\n",
        "## Deep Learning Technologies\n",
        "### Shruti Badrinarayanan - 016768141"
      ],
      "metadata": {
        "id": "I_TY8zHxY1LS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2\n",
        "Reproduce the results from Demo 2 utilizing the \"QMNIST\" dataset"
      ],
      "metadata": {
        "id": "4ntLqKt1I84q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "_BrJE-MSI-Kf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "# Load QMNIST dataset and preprocess\n",
        "train_dataset = datasets.QMNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.QMNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "iKpUkd41Jtf4",
        "outputId": "3dd0f895-5f67-444e-d5a3-b64242f19f25",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://raw.githubusercontent.com/facebookresearch/qmnist/master/qmnist-train-images-idx3-ubyte.gz to ./data/QMNIST/raw/qmnist-train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9704059/9704059 [00:00<00:00, 153015911.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/QMNIST/raw/qmnist-train-images-idx3-ubyte.gz to ./data/QMNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://raw.githubusercontent.com/facebookresearch/qmnist/master/qmnist-train-labels-idx2-int.gz to ./data/QMNIST/raw/qmnist-train-labels-idx2-int.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 463024/463024 [00:00<00:00, 22293611.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/QMNIST/raw/qmnist-train-labels-idx2-int.gz to ./data/QMNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://raw.githubusercontent.com/facebookresearch/qmnist/master/qmnist-test-images-idx3-ubyte.gz to ./data/QMNIST/raw/qmnist-test-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9742279/9742279 [00:00<00:00, 163768650.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/QMNIST/raw/qmnist-test-images-idx3-ubyte.gz to ./data/QMNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://raw.githubusercontent.com/facebookresearch/qmnist/master/qmnist-test-labels-idx2-int.gz to ./data/QMNIST/raw/qmnist-test-labels-idx2-int.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 526800/526800 [00:00<00:00, 17872500.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/QMNIST/raw/qmnist-test-labels-idx2-int.gz to ./data/QMNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Iterating and Visualizing the Dataset"
      ],
      "metadata": {
        "id": "A00skpJDS3r1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Define labels map\n",
        "labels_map = {\n",
        "    0: \"0\",\n",
        "    1: \"1\",\n",
        "    2: \"2\",\n",
        "    3: \"3\",\n",
        "    4: \"4\",\n",
        "    5: \"5\",\n",
        "    6: \"6\",\n",
        "    7: \"7\",\n",
        "    8: \"8\",\n",
        "    9: \"9\"\n",
        "}\n",
        "\n",
        "# Define transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# Load QMNIST dataset\n",
        "train_dataset = datasets.QMNIST(root='./data', train=True, download=True, transform=transform)\n",
        "\n",
        "# Create a figure to plot\n",
        "figure = plt.figure(figsize=(8, 8))\n",
        "cols, rows = 3, 3\n",
        "\n",
        "# Iterate over the dataset and plot samples\n",
        "for i in range(1, cols * rows + 1):\n",
        "    sample_idx = torch.randint(len(train_dataset), size=(1,)).item()\n",
        "    img, label = train_dataset[sample_idx]\n",
        "    figure.add_subplot(rows, cols, i)\n",
        "    plt.title(labels_map[label])\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        },
        "id": "1aTWwvPVSEQn",
        "outputId": "de25885b-e8e0-4eaf-f6c5-a9977ac499a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 9 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a figure to plot\n",
        "figure = plt.figure(figsize=(8, 8))\n",
        "cols, rows = 3, 3\n",
        "\n",
        "# Iterate over the test dataset and plot samples\n",
        "for i in range(1, cols * rows + 1):\n",
        "    sample_idx = torch.randint(len(test_dataset), size=(1,)).item()\n",
        "    img, label = test_dataset[sample_idx]\n",
        "    figure.add_subplot(rows, cols, i)\n",
        "    plt.title(labels_map[label])\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        },
        "id": "0bu-_rukSu77",
        "outputId": "5030f7cc-680f-4298-c0b2-192d81b86781"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 9 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the neural network architecture\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(28 * 28, 128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28 * 28)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Initialize the neural network\n",
        "model = MLP()"
      ],
      "metadata": {
        "id": "eBt_6_T0JxRZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Train the neural network\n",
        "num_epochs = 5\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        inputs, labels = data\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        if i % 100 == 99:  # print every 100 mini-batches\n",
        "            print(f'Epoch {epoch + 1}, Batch {i + 1}, Loss: {running_loss / 100}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "id": "i7LOPbrkJ3Pi",
        "outputId": "7349e3e9-3928-4dc8-eaa1-c2db041cbdba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Batch 100, Loss: 1.051395183801651\n",
            "Epoch 1, Batch 200, Loss: 0.45374462932348253\n",
            "Epoch 1, Batch 300, Loss: 0.39071386769413946\n",
            "Epoch 1, Batch 400, Loss: 0.33471844777464865\n",
            "Epoch 1, Batch 500, Loss: 0.30837334610521794\n",
            "Epoch 1, Batch 600, Loss: 0.30022230684757234\n",
            "Epoch 1, Batch 700, Loss: 0.2641004115343094\n",
            "Epoch 1, Batch 800, Loss: 0.2631072610616684\n",
            "Epoch 1, Batch 900, Loss: 0.2306192434579134\n",
            "Epoch 2, Batch 100, Loss: 0.2088735892623663\n",
            "Epoch 2, Batch 200, Loss: 0.21553051255643368\n",
            "Epoch 2, Batch 300, Loss: 0.20559132140129804\n",
            "Epoch 2, Batch 400, Loss: 0.1918110940232873\n",
            "Epoch 2, Batch 500, Loss: 0.17815559603273867\n",
            "Epoch 2, Batch 600, Loss: 0.18038600012660028\n",
            "Epoch 2, Batch 700, Loss: 0.1841022477671504\n",
            "Epoch 2, Batch 800, Loss: 0.1575042473524809\n",
            "Epoch 2, Batch 900, Loss: 0.15331582602113486\n",
            "Epoch 3, Batch 100, Loss: 0.13943775923922658\n",
            "Epoch 3, Batch 200, Loss: 0.15017410375177861\n",
            "Epoch 3, Batch 300, Loss: 0.1481042167171836\n",
            "Epoch 3, Batch 400, Loss: 0.12975529177114367\n",
            "Epoch 3, Batch 500, Loss: 0.14032627698034048\n",
            "Epoch 3, Batch 600, Loss: 0.13386961152777077\n",
            "Epoch 3, Batch 700, Loss: 0.14960231591016054\n",
            "Epoch 3, Batch 800, Loss: 0.13190857319161295\n",
            "Epoch 3, Batch 900, Loss: 0.11474453995004297\n",
            "Epoch 4, Batch 100, Loss: 0.11026755799539387\n",
            "Epoch 4, Batch 200, Loss: 0.11439050622284412\n",
            "Epoch 4, Batch 300, Loss: 0.11557521423324943\n",
            "Epoch 4, Batch 400, Loss: 0.11401785180903971\n",
            "Epoch 4, Batch 500, Loss: 0.11234834151342511\n",
            "Epoch 4, Batch 600, Loss: 0.10434356423094869\n",
            "Epoch 4, Batch 700, Loss: 0.10669080758467317\n",
            "Epoch 4, Batch 800, Loss: 0.1050957614928484\n",
            "Epoch 4, Batch 900, Loss: 0.11944030714221299\n",
            "Epoch 5, Batch 100, Loss: 0.08688490798696875\n",
            "Epoch 5, Batch 200, Loss: 0.08644109255634248\n",
            "Epoch 5, Batch 300, Loss: 0.09732077913358808\n",
            "Epoch 5, Batch 400, Loss: 0.0915635250415653\n",
            "Epoch 5, Batch 500, Loss: 0.09682046387344599\n",
            "Epoch 5, Batch 600, Loss: 0.10352619651239366\n",
            "Epoch 5, Batch 700, Loss: 0.09731933051720261\n",
            "Epoch 5, Batch 800, Loss: 0.09251443727873265\n",
            "Epoch 5, Batch 900, Loss: 0.10935049970634282\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in train_loader:\n",
        "        images, labels = data\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "print(f'Accuracy on training set: {round(correct / total * 100, 3)}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZ1Osg8MnMY-",
        "outputId": "c061ea57-dac3-4245-9932-ef92a7579d57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on training set: 97.545%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "        images, labels = data\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "print(f'Accuracy on test set: {round(correct / total * 100, 3)}%')"
      ],
      "metadata": {
        "id": "3DXPLgQJJ6Aq",
        "outputId": "63b42b8a-88a1-4700-fb48-de7713e62a66",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on test set: 96.478%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model and store predictions\n",
        "model.eval()\n",
        "predictions = []\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "        images, labels = data\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        predictions.extend(predicted.numpy())  # Store predictions\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()"
      ],
      "metadata": {
        "id": "E1nluT6ALxSX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get one test image and its label\n",
        "image, label = images[1], labels[1]\n",
        "\n",
        "# Reshape the image tensor to a 28x28 shape\n",
        "image = image.view(28, 28)\n",
        "\n",
        "# Convert the image tensor to a numpy array for visualization\n",
        "image_numpy = image.numpy()\n",
        "\n",
        "# Show the image\n",
        "plt.imshow(image_numpy, cmap='gray')\n",
        "plt.title(f'Predicted Label: {predictions[1]}, Actual Label: {label.item()}')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MvdJMXaMMvUD",
        "outputId": "12196ece-1140-48be-8fa0-5d01b9908592",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3\n",
        "**Report on the results in terms of prediction accuracy on the train and test datasets:**\n",
        "- Accuracy on training set: 97.545%\n",
        "- Accuracy on test set: 96.478%"
      ],
      "metadata": {
        "id": "uSwtA2a1d-ec"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4\n",
        "**Chosen Proposed modification:**\n",
        "- Increase the current number of nodes in the layer to 256\n",
        "\n",
        "**Hypothesize how it would change the performance results:**\n",
        "- Expectation is that the performance would be better. Increasing the number of units should increase the representation power of the model, and thus capture complex relationships between the input features."
      ],
      "metadata": {
        "id": "60C6nda6eLw4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 5\n",
        "Modify the model based on the chosen method and train\n",
        "\n"
      ],
      "metadata": {
        "id": "CyVI6BfBeaNJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the neural network architecture\n",
        "class MLP2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP2, self).__init__()\n",
        "        self.fc1 = nn.Linear(28 * 28, 256)\n",
        "        self.fc2 = nn.Linear(256, 256)\n",
        "        self.fc3 = nn.Linear(256, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28 * 28)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Initialize the neural network\n",
        "model = MLP2()\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Train the neural network\n",
        "num_epochs = 5\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        inputs, labels = data\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        if i % 100 == 99:  # print every 100 mini-batches\n",
        "            print(f'Epoch {epoch + 1}, Batch {i + 1}, Loss: {running_loss / 100}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')\n",
        "\n",
        "# Evaluate the model on train set\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in train_loader:\n",
        "        images, labels = data\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "print(f'\\nAccuracy on training set: {round(correct / total * 100, 3)}%')\n",
        "\n",
        "# Evaluate the model on test set\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "        images, labels = data\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "print(f'\\nAccuracy on test set: {round(correct / total * 100, 3)}%')"
      ],
      "metadata": {
        "id": "6HRirZf5edZV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2789ad8-35fe-47e5-895c-06a46d180cd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Batch 100, Loss: 0.8071736365556716\n",
            "Epoch 1, Batch 200, Loss: 0.40492315232753756\n",
            "Epoch 1, Batch 300, Loss: 0.3472131535410881\n",
            "Epoch 1, Batch 400, Loss: 0.29048687145113944\n",
            "Epoch 1, Batch 500, Loss: 0.267886396124959\n",
            "Epoch 1, Batch 600, Loss: 0.22987685419619083\n",
            "Epoch 1, Batch 700, Loss: 0.20978261969983578\n",
            "Epoch 1, Batch 800, Loss: 0.20534527525305749\n",
            "Epoch 1, Batch 900, Loss: 0.1906840530782938\n",
            "Epoch 2, Batch 100, Loss: 0.1589204926788807\n",
            "Epoch 2, Batch 200, Loss: 0.15620957942679525\n",
            "Epoch 2, Batch 300, Loss: 0.1602341916412115\n",
            "Epoch 2, Batch 400, Loss: 0.1448148599267006\n",
            "Epoch 2, Batch 500, Loss: 0.154100420223549\n",
            "Epoch 2, Batch 600, Loss: 0.13776653269305825\n",
            "Epoch 2, Batch 700, Loss: 0.12482802143320441\n",
            "Epoch 2, Batch 800, Loss: 0.13843017285689713\n",
            "Epoch 2, Batch 900, Loss: 0.13583758232183754\n",
            "Epoch 3, Batch 100, Loss: 0.10329044912010431\n",
            "Epoch 3, Batch 200, Loss: 0.12455667938105762\n",
            "Epoch 3, Batch 300, Loss: 0.10073038604110479\n",
            "Epoch 3, Batch 400, Loss: 0.10945549869909882\n",
            "Epoch 3, Batch 500, Loss: 0.10258176507428289\n",
            "Epoch 3, Batch 600, Loss: 0.10284815507009626\n",
            "Epoch 3, Batch 700, Loss: 0.10041646348312497\n",
            "Epoch 3, Batch 800, Loss: 0.09911579543724656\n",
            "Epoch 3, Batch 900, Loss: 0.0996888238331303\n",
            "Epoch 4, Batch 100, Loss: 0.08420579159632326\n",
            "Epoch 4, Batch 200, Loss: 0.08118491069413722\n",
            "Epoch 4, Batch 300, Loss: 0.07760304818861187\n",
            "Epoch 4, Batch 400, Loss: 0.09529290122445673\n",
            "Epoch 4, Batch 500, Loss: 0.08812496021389961\n",
            "Epoch 4, Batch 600, Loss: 0.10099714292678982\n",
            "Epoch 4, Batch 700, Loss: 0.08425796969793736\n",
            "Epoch 4, Batch 800, Loss: 0.080492271669209\n",
            "Epoch 4, Batch 900, Loss: 0.09039695331826807\n",
            "Epoch 5, Batch 100, Loss: 0.06270382652059198\n",
            "Epoch 5, Batch 200, Loss: 0.0662050730921328\n",
            "Epoch 5, Batch 300, Loss: 0.07605685861315578\n",
            "Epoch 5, Batch 400, Loss: 0.07664446657756344\n",
            "Epoch 5, Batch 500, Loss: 0.06437447265256196\n",
            "Epoch 5, Batch 600, Loss: 0.062251371466554704\n",
            "Epoch 5, Batch 700, Loss: 0.07788448627106845\n",
            "Epoch 5, Batch 800, Loss: 0.07875045237131417\n",
            "Epoch 5, Batch 900, Loss: 0.07082748709246517\n",
            "Finished Training\n",
            "\n",
            "Accuracy on training set: 98.033%\n",
            "\n",
            "Accuracy on test set: 96.983%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 6\n",
        "**Report on the results of the modified model and if it matches your hypothesis:**\n",
        "- Accuracy on training set: 98.033%\n",
        "- Accuracy on test set: 96.983%\n",
        "\n",
        "As you can see, the test accuracy is slightly higher (+0.5pp) on this modified model due to the increase in the number of units in the hidden layers."
      ],
      "metadata": {
        "id": "TzRBv0uEed_H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 7\n",
        "Experiment with different optimizers, loss functions, dropout, and activation functions, and observe the change in performance as you tune these hyperparameters.\n",
        "\n",
        "**I conducted various experiments iteratively, and changed the hyperparamters based on the results of the experiment before.**"
      ],
      "metadata": {
        "id": "SNpUAk1SekeY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experiment 1\n",
        "- Using LeakyRELU as the activation function"
      ],
      "metadata": {
        "id": "uHtBeqnprYB9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the neural network architecture\n",
        "class MLP3(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP3, self).__init__()\n",
        "        self.fc1 = nn.Linear(28 * 28, 256)\n",
        "        self.fc2 = nn.Linear(256, 256)\n",
        "        self.fc3 = nn.Linear(256, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28 * 28)\n",
        "        m = nn.LeakyReLU(0.1)\n",
        "        x = m(self.fc1(x))\n",
        "        x = m(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Initialize the neural network\n",
        "model = MLP3()\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Train the neural network\n",
        "num_epochs = 5\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        inputs, labels = data\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        if i % 100 == 99:  # print every 100 mini-batches\n",
        "            print(f'Epoch {epoch + 1}, Batch {i + 1}, Loss: {running_loss / 100}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')\n",
        "\n",
        "# Evaluate the model on train set\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in train_loader:\n",
        "        images, labels = data\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "print(f'\\nAccuracy on training set: {round(correct / total * 100, 3)}%')\n",
        "\n",
        "# Evaluate the model on test set\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "        images, labels = data\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "print(f'\\nAccuracy on test set: {round(correct / total * 100, 3)}%')"
      ],
      "metadata": {
        "id": "bjqchekReoMW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fb55eb4-2854-4a98-9d20-5235a2cac33e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Batch 100, Loss: 0.7568198479712009\n",
            "Epoch 1, Batch 200, Loss: 0.39976607978343964\n",
            "Epoch 1, Batch 300, Loss: 0.34245645843446254\n",
            "Epoch 1, Batch 400, Loss: 0.26382544726133345\n",
            "Epoch 1, Batch 500, Loss: 0.25990179635584354\n",
            "Epoch 1, Batch 600, Loss: 0.23463215976953505\n",
            "Epoch 1, Batch 700, Loss: 0.2089624697342515\n",
            "Epoch 1, Batch 800, Loss: 0.2059041927754879\n",
            "Epoch 1, Batch 900, Loss: 0.18694675870239735\n",
            "Epoch 2, Batch 100, Loss: 0.14455784048885106\n",
            "Epoch 2, Batch 200, Loss: 0.15795419041067363\n",
            "Epoch 2, Batch 300, Loss: 0.14165018441155552\n",
            "Epoch 2, Batch 400, Loss: 0.15178567305207252\n",
            "Epoch 2, Batch 500, Loss: 0.14831442189402877\n",
            "Epoch 2, Batch 600, Loss: 0.13280720888637007\n",
            "Epoch 2, Batch 700, Loss: 0.1156093378085643\n",
            "Epoch 2, Batch 800, Loss: 0.12313736679032444\n",
            "Epoch 2, Batch 900, Loss: 0.13748362174257636\n",
            "Epoch 3, Batch 100, Loss: 0.10562972147017717\n",
            "Epoch 3, Batch 200, Loss: 0.1169363341666758\n",
            "Epoch 3, Batch 300, Loss: 0.10485320556908846\n",
            "Epoch 3, Batch 400, Loss: 0.1014597584027797\n",
            "Epoch 3, Batch 500, Loss: 0.10746630642563104\n",
            "Epoch 3, Batch 600, Loss: 0.09632378451526165\n",
            "Epoch 3, Batch 700, Loss: 0.10071750884875655\n",
            "Epoch 3, Batch 800, Loss: 0.08768256187438965\n",
            "Epoch 3, Batch 900, Loss: 0.11477336847223342\n",
            "Epoch 4, Batch 100, Loss: 0.09259324757149442\n",
            "Epoch 4, Batch 200, Loss: 0.08282080902718007\n",
            "Epoch 4, Batch 300, Loss: 0.0725642140675336\n",
            "Epoch 4, Batch 400, Loss: 0.08372100478503854\n",
            "Epoch 4, Batch 500, Loss: 0.09130700716748834\n",
            "Epoch 4, Batch 600, Loss: 0.08584454915486277\n",
            "Epoch 4, Batch 700, Loss: 0.09414727118331939\n",
            "Epoch 4, Batch 800, Loss: 0.08335652980022132\n",
            "Epoch 4, Batch 900, Loss: 0.0824344675661996\n",
            "Epoch 5, Batch 100, Loss: 0.06207596717402339\n",
            "Epoch 5, Batch 200, Loss: 0.07337925009895116\n",
            "Epoch 5, Batch 300, Loss: 0.07501433210447431\n",
            "Epoch 5, Batch 400, Loss: 0.09060302069410682\n",
            "Epoch 5, Batch 500, Loss: 0.06637288065161556\n",
            "Epoch 5, Batch 600, Loss: 0.06267041023238562\n",
            "Epoch 5, Batch 700, Loss: 0.07988531130366028\n",
            "Epoch 5, Batch 800, Loss: 0.07245142576284706\n",
            "Epoch 5, Batch 900, Loss: 0.07411162466974928\n",
            "Finished Training\n",
            "\n",
            "Accuracy on training set: 98.092%\n",
            "\n",
            "Accuracy on test set: 96.88%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Experiment 1, Observation: There is a minimal change in model performance.**"
      ],
      "metadata": {
        "id": "0vLdDwuus_ad"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experiment 2\n",
        "- Adding dropout\n",
        "- Using RELU as activation function"
      ],
      "metadata": {
        "id": "BnqjuR3ZtLIc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the neural network architecture\n",
        "class MLP4(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP4, self).__init__()\n",
        "        self.fc1 = nn.Linear(28 * 28, 256)\n",
        "        self.dropout = nn.Dropout(0.4)\n",
        "        self.fc2 = nn.Linear(256, 256)\n",
        "        self.fc3 = nn.Linear(256, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28 * 28)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Initialize the neural network\n",
        "model = MLP4()\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Train the neural network\n",
        "num_epochs = 5\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        inputs, labels = data\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        if i % 100 == 99:  # print every 100 mini-batches\n",
        "            print(f'Epoch {epoch + 1}, Batch {i + 1}, Loss: {running_loss / 100}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')\n",
        "\n",
        "# Evaluate the model on train set\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in train_loader:\n",
        "        images, labels = data\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "print(f'\\nAccuracy on training set: {round(correct / total * 100, 3)}%')\n",
        "\n",
        "# Evaluate the model on test set\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "        images, labels = data\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "print(f'\\nAccuracy on test set: {round(correct / total * 100, 3)}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2qd9sTctKft",
        "outputId": "b1585601-30c6-4831-a93d-0ba2d270e9b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Batch 100, Loss: 1.1522636383771896\n",
            "Epoch 1, Batch 200, Loss: 0.5623406600952149\n",
            "Epoch 1, Batch 300, Loss: 0.46236045852303503\n",
            "Epoch 1, Batch 400, Loss: 0.41659941509366033\n",
            "Epoch 1, Batch 500, Loss: 0.3889280703663826\n",
            "Epoch 1, Batch 600, Loss: 0.3597530922293663\n",
            "Epoch 1, Batch 700, Loss: 0.34314409546554087\n",
            "Epoch 1, Batch 800, Loss: 0.325596454590559\n",
            "Epoch 1, Batch 900, Loss: 0.35319829657673835\n",
            "Epoch 2, Batch 100, Loss: 0.29220532104372976\n",
            "Epoch 2, Batch 200, Loss: 0.28812515318393705\n",
            "Epoch 2, Batch 300, Loss: 0.2845014062523842\n",
            "Epoch 2, Batch 400, Loss: 0.2705543936789036\n",
            "Epoch 2, Batch 500, Loss: 0.2790458967536688\n",
            "Epoch 2, Batch 600, Loss: 0.26851860925555227\n",
            "Epoch 2, Batch 700, Loss: 0.29175366401672365\n",
            "Epoch 2, Batch 800, Loss: 0.2680337828397751\n",
            "Epoch 2, Batch 900, Loss: 0.2724119249731302\n",
            "Epoch 3, Batch 100, Loss: 0.23873983465135099\n",
            "Epoch 3, Batch 200, Loss: 0.24468070637434722\n",
            "Epoch 3, Batch 300, Loss: 0.22878408271819353\n",
            "Epoch 3, Batch 400, Loss: 0.22917100992053746\n",
            "Epoch 3, Batch 500, Loss: 0.24067442059516908\n",
            "Epoch 3, Batch 600, Loss: 0.2453754373639822\n",
            "Epoch 3, Batch 700, Loss: 0.24188375927507877\n",
            "Epoch 3, Batch 800, Loss: 0.2259769035875797\n",
            "Epoch 3, Batch 900, Loss: 0.2264163015782833\n",
            "Epoch 4, Batch 100, Loss: 0.2326659408211708\n",
            "Epoch 4, Batch 200, Loss: 0.21433570601046084\n",
            "Epoch 4, Batch 300, Loss: 0.20752811532467605\n",
            "Epoch 4, Batch 400, Loss: 0.22453952483832837\n",
            "Epoch 4, Batch 500, Loss: 0.21373197048902512\n",
            "Epoch 4, Batch 600, Loss: 0.21115236092358827\n",
            "Epoch 4, Batch 700, Loss: 0.20990378074347973\n",
            "Epoch 4, Batch 800, Loss: 0.2151985891535878\n",
            "Epoch 4, Batch 900, Loss: 0.20334661221131684\n",
            "Epoch 5, Batch 100, Loss: 0.19920878738164902\n",
            "Epoch 5, Batch 200, Loss: 0.1835948555544019\n",
            "Epoch 5, Batch 300, Loss: 0.20621265698224306\n",
            "Epoch 5, Batch 400, Loss: 0.2188256883993745\n",
            "Epoch 5, Batch 500, Loss: 0.20579337172210216\n",
            "Epoch 5, Batch 600, Loss: 0.19805532395839692\n",
            "Epoch 5, Batch 700, Loss: 0.20414221964776516\n",
            "Epoch 5, Batch 800, Loss: 0.20385809242725372\n",
            "Epoch 5, Batch 900, Loss: 0.196414747685194\n",
            "Finished Training\n",
            "\n",
            "Accuracy on training set: 97.123%\n",
            "\n",
            "Accuracy on test set: 96.343%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Experiment 2, Observation: There is a minimal change in model performance here also (similar to experiment 1).**"
      ],
      "metadata": {
        "id": "lNwt_5aavmPj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experiment 2\n",
        "- Optimizer : SGD with Momentum\n",
        "- Remove Dropout\n",
        "- Keep Loss Function as it is. (CrossEntropyLoss is a good loss function for image classification tasks)\n",
        "- Change epochs to 10"
      ],
      "metadata": {
        "id": "aoTKZ3fFv03A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the neural network architecture\n",
        "class MLP5(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP5, self).__init__()\n",
        "        self.fc1 = nn.Linear(28 * 28, 256)\n",
        "        self.fc2 = nn.Linear(256, 256)\n",
        "        self.fc3 = nn.Linear(256, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28 * 28)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Initialize the neural network\n",
        "model = MLP5()\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Train the neural network\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        inputs, labels = data\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        if i % 100 == 99:  # print every 100 mini-batches\n",
        "            print(f'Epoch {epoch + 1}, Batch {i + 1}, Loss: {running_loss / 100}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')\n",
        "\n",
        "# Evaluate the model on train set\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in train_loader:\n",
        "        images, labels = data\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "print(f'\\nAccuracy on training set: {round(correct / total * 100, 3)}%')\n",
        "\n",
        "# Evaluate the model on test set\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "        images, labels = data\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "print(f'\\nAccuracy on test set: {round(correct / total * 100, 3)}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2ZSDNhSwELr",
        "outputId": "aafc3f25-0dcf-4a6d-dfd7-5ce6af3b4780"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Batch 100, Loss: 2.213886158466339\n",
            "Epoch 1, Batch 200, Loss: 1.862549875974655\n",
            "Epoch 1, Batch 300, Loss: 1.2826274049282074\n",
            "Epoch 1, Batch 400, Loss: 0.8781676918268204\n",
            "Epoch 1, Batch 500, Loss: 0.6879666876792908\n",
            "Epoch 1, Batch 600, Loss: 0.5750034096837043\n",
            "Epoch 1, Batch 700, Loss: 0.5203057399392128\n",
            "Epoch 1, Batch 800, Loss: 0.47979888543486593\n",
            "Epoch 1, Batch 900, Loss: 0.453942568898201\n",
            "Epoch 2, Batch 100, Loss: 0.41257673159241676\n",
            "Epoch 2, Batch 200, Loss: 0.4241723296046257\n",
            "Epoch 2, Batch 300, Loss: 0.3782146629691124\n",
            "Epoch 2, Batch 400, Loss: 0.35747367531061175\n",
            "Epoch 2, Batch 500, Loss: 0.36062595024704935\n",
            "Epoch 2, Batch 600, Loss: 0.3587823875248432\n",
            "Epoch 2, Batch 700, Loss: 0.34613695815205575\n",
            "Epoch 2, Batch 800, Loss: 0.33072088211774825\n",
            "Epoch 2, Batch 900, Loss: 0.3385790821909904\n",
            "Epoch 3, Batch 100, Loss: 0.3370643675327301\n",
            "Epoch 3, Batch 200, Loss: 0.3387794373929501\n",
            "Epoch 3, Batch 300, Loss: 0.30916458889842036\n",
            "Epoch 3, Batch 400, Loss: 0.31826857417821885\n",
            "Epoch 3, Batch 500, Loss: 0.30405941501259803\n",
            "Epoch 3, Batch 600, Loss: 0.32090407475829125\n",
            "Epoch 3, Batch 700, Loss: 0.29746614389121534\n",
            "Epoch 3, Batch 800, Loss: 0.28658828414976595\n",
            "Epoch 3, Batch 900, Loss: 0.2980538690090179\n",
            "Epoch 4, Batch 100, Loss: 0.28360510475933554\n",
            "Epoch 4, Batch 200, Loss: 0.28112616151571274\n",
            "Epoch 4, Batch 300, Loss: 0.2903986569494009\n",
            "Epoch 4, Batch 400, Loss: 0.29773803740739824\n",
            "Epoch 4, Batch 500, Loss: 0.2935268172621727\n",
            "Epoch 4, Batch 600, Loss: 0.2677741742879152\n",
            "Epoch 4, Batch 700, Loss: 0.2752408237755299\n",
            "Epoch 4, Batch 800, Loss: 0.28271770775318145\n",
            "Epoch 4, Batch 900, Loss: 0.2804897201806307\n",
            "Epoch 5, Batch 100, Loss: 0.2904805614054203\n",
            "Epoch 5, Batch 200, Loss: 0.24415116563439368\n",
            "Epoch 5, Batch 300, Loss: 0.2425255323201418\n",
            "Epoch 5, Batch 400, Loss: 0.269397227242589\n",
            "Epoch 5, Batch 500, Loss: 0.2607550687342882\n",
            "Epoch 5, Batch 600, Loss: 0.24785903327167033\n",
            "Epoch 5, Batch 700, Loss: 0.26461022466421125\n",
            "Epoch 5, Batch 800, Loss: 0.26763714708387853\n",
            "Epoch 5, Batch 900, Loss: 0.2444200573861599\n",
            "Epoch 6, Batch 100, Loss: 0.22471575178205966\n",
            "Epoch 6, Batch 200, Loss: 0.23547520428895952\n",
            "Epoch 6, Batch 300, Loss: 0.22895860381424427\n",
            "Epoch 6, Batch 400, Loss: 0.25397114232182505\n",
            "Epoch 6, Batch 500, Loss: 0.23292261563241481\n",
            "Epoch 6, Batch 600, Loss: 0.22787105277180672\n",
            "Epoch 6, Batch 700, Loss: 0.24134571082890033\n",
            "Epoch 6, Batch 800, Loss: 0.23838624455034732\n",
            "Epoch 6, Batch 900, Loss: 0.23759388621896504\n",
            "Epoch 7, Batch 100, Loss: 0.22535858895629646\n",
            "Epoch 7, Batch 200, Loss: 0.22235272102057935\n",
            "Epoch 7, Batch 300, Loss: 0.2245586221665144\n",
            "Epoch 7, Batch 400, Loss: 0.2278503219783306\n",
            "Epoch 7, Batch 500, Loss: 0.2201587587222457\n",
            "Epoch 7, Batch 600, Loss: 0.19998127423226833\n",
            "Epoch 7, Batch 700, Loss: 0.21365623578429221\n",
            "Epoch 7, Batch 800, Loss: 0.1916272623091936\n",
            "Epoch 7, Batch 900, Loss: 0.20722530722618104\n",
            "Epoch 8, Batch 100, Loss: 0.20535265773534775\n",
            "Epoch 8, Batch 200, Loss: 0.2010168418288231\n",
            "Epoch 8, Batch 300, Loss: 0.20109574757516385\n",
            "Epoch 8, Batch 400, Loss: 0.20216618053615093\n",
            "Epoch 8, Batch 500, Loss: 0.18956417709589005\n",
            "Epoch 8, Batch 600, Loss: 0.19816962357610465\n",
            "Epoch 8, Batch 700, Loss: 0.18817110631614922\n",
            "Epoch 8, Batch 800, Loss: 0.1958182853087783\n",
            "Epoch 8, Batch 900, Loss: 0.19222723223268987\n",
            "Epoch 9, Batch 100, Loss: 0.175272511318326\n",
            "Epoch 9, Batch 200, Loss: 0.20100397106260062\n",
            "Epoch 9, Batch 300, Loss: 0.16792689375579356\n",
            "Epoch 9, Batch 400, Loss: 0.18559948673471807\n",
            "Epoch 9, Batch 500, Loss: 0.18056661076843739\n",
            "Epoch 9, Batch 600, Loss: 0.17385825950652362\n",
            "Epoch 9, Batch 700, Loss: 0.19567847035825253\n",
            "Epoch 9, Batch 800, Loss: 0.18042858250439167\n",
            "Epoch 9, Batch 900, Loss: 0.17389776818454267\n",
            "Epoch 10, Batch 100, Loss: 0.165054417476058\n",
            "Epoch 10, Batch 200, Loss: 0.17609842862933875\n",
            "Epoch 10, Batch 300, Loss: 0.16537904571741818\n",
            "Epoch 10, Batch 400, Loss: 0.16151050563901662\n",
            "Epoch 10, Batch 500, Loss: 0.1636595681682229\n",
            "Epoch 10, Batch 600, Loss: 0.16707821883261204\n",
            "Epoch 10, Batch 700, Loss: 0.17080596428364514\n",
            "Epoch 10, Batch 800, Loss: 0.17007707063108682\n",
            "Epoch 10, Batch 900, Loss: 0.1652921449765563\n",
            "Finished Training\n",
            "\n",
            "Accuracy on training set: 95.517%\n",
            "\n",
            "Accuracy on test set: 94.965%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Experiment 3, Observation: The model performance is less as seen above, showing us that Adam is much more powerful than SGD with momentum.**"
      ],
      "metadata": {
        "id": "mHoJud-oyCYG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 8\n",
        "Show an example of a backpropagation algorithm by hand (one round of forward step and backward step on a smaller network by performing derivatives by hand instead of using coding libraries)\n",
        "\n",
        "- Separate file uploaded for this."
      ],
      "metadata": {
        "id": "BFy8Z4R7eo2E"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}